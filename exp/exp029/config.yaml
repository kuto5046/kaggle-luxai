basic:
  seed: 42
  n_envs: 24
  n_steps: 360
  step_count: 50000000 # 50M
  pretrained_path: best_model.zip

resume:
  is_resume: False
  run_id: devout-totem-367  # run id in wandb
  resume_num_timesteps: 0

callbacks:  
  eval:
    best_model_save_path: './models/'
    # log_path: './models/'
    eval_freq: 3600  # Run it every 10 training iterations
    n_eval_episodes: 3  # Run 5 games
    deterministic: False
    render: False

  checkpoints:
    save_freq: 50000  # 1,200,000
    save_path: './models/'
    name_prefix: 'rl_model'
    verbose: 0

model:
    model_update_step_freq: 50000
    model_arche: "cnn"  # "cnn" or "mlp"
    params:
      verbose: 0
      tensorboard_log: "./tensorboard/"
      learning_rate: 0.001
      gamma: 0.998
      gae_lambda: 0.95
      batch_size: 1024
      n_steps: 1024